# Read the file outputted by the Logging Interceptor Plugin
input {
  file {
    #path => "C:/ERMS/ERMS-0/jboss-a-mq-6.0.0.redhat-024/log/logging-interceptor.log"
    path => "D:/ERMS/ERMS-30/jboss-a-mq-6.0.0.redhat-024/log/logging-interceptor.log"
    start_position => "beginning"
    #sincedb_path => "C:/ERMS/FM-0/logstash/data/sincedb"
    sincedb_path => "D:/ERMS/FM-30/logstash/data/sincedb"
  }
}

# Parse input file lines and assign parsed values to logstash variables
filter {
  grok {
    match => ["message", "%{DATA:Date}\,%{NOTSPACE:MessageId}\,%{NOTSPACE:Action}\,%{NOTSPACE:ProtocolId}\,%{NOTSPACE:ProtocolVersion}\,%{NOTSPACE:Sender}\,%{NOTSPACE:Receiver}\,%{NOTSPACE:BrokerName}\,%{NOTSPACE:MessageIdentifier}\,%{NOTSPACE:CorrelationId}\,%{NOTSPACE:Destination}"]
  }
}

# Write onto the Flow Monitor database
output {
  jdbc {
    driver_class => "com.microsoft.sqlserver.jdbc.SQLServerDriver"
    connection_string => "jdbc:sqlserver://FR03PCC836;databaseName=IP_FM_ERMS_31;user=appuser_erms31_fm;password=***;autoReconnect=true;"
    statement => ["INSERT INTO Traces (traceSqlId, traceCategoryIncId, traceCategorySqlId, traceCode, customField1, customField2, customField3, customField4, customField5, customField7, customField8, customField9, customField10, modifiedOn)	VALUES(?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)", 0, 1, 0, "%{MessageId}", "%{Action}", "%{ProtocolId}", "%{ProtocolVersion}", "%{Sender}", "%{Receiver}", "%{MessageIdentifier}", "%{CorrelationId}", "%{Destination}", "%{BrokerName}", "%{Date}"]
  }
}
